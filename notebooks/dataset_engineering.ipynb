{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9e02048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3833ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "Your task is to summarize this markdown text into an one paragraph text, keeping the main key points.\n",
    "Discard information that is not relevant.\n",
    "Discard any symbles that are not relevant for the semantic structure.\n",
    "The text contain a kind of documentation, try to keep the examples highligted with a ``` between quotes (\") among the paragraph. \n",
    "\n",
    "Text to summarize: {}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5a69ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for (root, dirs, files) in os.walk(\"../documents\"):\n",
    "    for file in files:\n",
    "        pwd = f'{root}/{file}'\n",
    "        with open(pwd, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        documents.append({\n",
    "            'name': file,\n",
    "            'content': content\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb915796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'path': '../documents/introduction.md', 'content': \"# Introduction to AI Agents\\n\\n\\nAgents are revolutionizing the way we approach complex tasks, leveraging the power of large language models (LLMs) to work on our behalf and achieve remarkable results. In this guide we will dive into the fundamentals of AI agents, exploring their capabilities, design patterns, and potential applications.\\n\\n## What is an Agent?\\n\\n![Agent Components](../../img/agents/agent-components.png)\\n\\nIn this guide, we refer to an agent as an LLM-powered system designed to take actions and solve complex tasks autonomously. Unlike traditional LLMs, AI agents go beyond simple text generation. They are equipped with additional capabilities, including:\\n\\n- **Planning and reflection:** AI agents can analyze a problem, break it down into steps, and adjust their approach based on new information.\\n- **Tool access:** They can interact with external tools and resources, such as databases, APIs, and software applications, to gather information and execute actions.\\n- **Memory:** AI agents can store and retrieve information, allowing them to learn from past experiences and make more informed decisions.\\n\\nThis lecture discusses the concept of AI agents and their significance in the realm of artificial intelligence.\\n\\n## Why build with Agents?\\n\\nWhile large language models (LLMs) excel at simple, narrow tasks like translation or email generation, they fall short when dealing with complex, broader tasks that require multiple steps, planning, and reasoning. These complex tasks often necessitate access to external tools and information beyond the LLM's knowledge base.\\n\\nFor example, developing a marketing strategy might involve researching competitors, analyzing market trends, and accessing company-specific data. These actions necessitate real-world information, the latest insights, and internal company data, which a standalone LLM might not have access to.\\n\\nAI agents bridge this gap by combining the capabilities of LLMs with additional features such as memory, planning, and external tools.\\n\\nBy leveraging these abilities, AI agents can effectively tackle complex tasks like:\\n\\n- Developing marketing strategies\\n- Planning events\\n- Providing customer support\\n\\n## Common Use Cases for AI Agents\\n\\nHere is a non-exhaustive list of common use cases where agents are being applied in the industry:\\n\\n- **Recommendation systems:** Personalizing suggestions for products, services, or content.\\n- **Customer support systems:** Handling inquiries, resolving issues, and providing assistance.\\n- **Research:** Conducting in-depth investigations across various domains, such as legal, finance, and health.\\n- **E-commerce applications:** Facilitating online shopping experiences, managing orders, and providing personalized recommendations.\\n- **Booking:** Assisting with travel arrangements and event planning.\\n- **Reporting:** Analyzing vast amounts of data and generating comprehensive reports.\\n- **Financial analysis:** Analyzing market trends, assess financial data, and generate reports with unprecedented speed and accuracy.\\n\"}, {'path': '../documents/coding.md', 'content': '# Generating Code\\n\\n\\n\\n\\nLLMs like ChatGPT are very effective at code generation. In this section, we will cover many examples of how to use ChatGPT for code generation.\\n\\nThe OpenAI\\'s Playground (Chat Mode) and the `gpt-3.5-turbo` model are used for all examples below.\\n\\nAs with all chat models from OpenAI, you can use a `System Message` to define the behavior and format of the responses. We will use the following System Message for the prompt examples:\\n\\n```\\nYou are a helpful code assistant that can teach a junior developer how to code. Your language of choice is Python. Don\\'t explain the code, just generate the code block itself.\\n```\\n\\n## Basic Example\\n\\nThe `User Message` will then be the prompt itself with the instruction of the specific code you want the model to generate. Below is a snapshot of the first basic prompt for code generation. Note that the final code was generated by the `Assistant`.\\n\\n\\n\\nHere is the prompt if you want to try it yourself: \\n\\n```\\nWrite code that asks the user for their name and say \"Hello\"\\n```\\n\\n## Turn Comments Into Code\\n\\nYou can also use the code generation capabilities of these LLMs to generate code from comments alone. Let\\'s look at another example that passes the instructions as a comment block:\\n\\n*Prompt:*\\n```\\n\"\"\"\\n1. Create a list of movies\\n2. Create a list of ratings for these movies\\n3. Combine them to make a json object of 10 movies with their ratings.\\n\"\"\"\\n```\\n\\n*Output:*\\n```python\\nmovies = [\"The Shawshank Redemption\", \"The Godfather\", \"The Dark Knight\", \"Schindler\\'s List\", \"Pulp Fiction\", \"The Lord of the Rings: The Return of the King\", \"Forrest Gump\", \"Star Wars: Episode V - The Empire Strikes Back\", \"Inception\", \"The Silence of the Lambs\"]\\n\\nratings = [9.3, 9.2, 9.0, 8.9, 8.9, 8.9, 8.8, 8.7, 8.7, 8.6]\\n\\nmovie_ratings = {}\\n\\nfor i in range(len(movies)):\\n    movie_ratings[movies[i]] = ratings[i]\\n\\njson_object = json.dumps(movie_ratings, indent=4)\\n\\nprint(json_object)\\n```\\n\\nThe generated code looks like working code. However, the output doesn\\'t contain an important `import` statement, i.e., `import json`. While these models generate working code, you must pay close attention to small details like this and always make sure to test your code. \\n\\n## Complete Functions or Next Line\\n\\nThese LLMs have also been incorporated into tools like GitHub Copilot which makes them useful for developers. One useful feature is the ability of the model to complete functions. \\n\\n*Prompt:*\\n```python\\n# function to multiply two numbers and add 75 to it\\n\\ndef multiply(\\n```\\n\\n*Output:*\\n```python\\na, b):\\n    result = a * b\\n    result += 75\\n    return result\\n```\\n\\n## MySQL Query Generation\\n\\nBesides the basic code generation example above, you can use the model to generate useful code that could be used in other aspects of programming like creating and testing MySQL queries. \\n\\nLet\\'s say you have a dataset with some information which you can include as part of the prompt and then instruct it to generate a specific query. For example:\\n\\n```\\n\"\"\"\\nTable departments, columns = [DepartmentId, DepartmentName]\\nTable students, columns = [DepartmentId, StudentId, StudentName]\\nCreate a MySQL query for all students in the Computer Science department\\n\"\"\"\\n```\\n\\n*Output:*\\n```mysql\\nSELECT students.StudentId, students.StudentName\\nFROM students\\nINNER JOIN departments\\nON students.DepartmentId = departments.DepartmentId\\nWHERE departments.DepartmentName = \\'Computer Science\\';\\n```\\n\\nThe model generates a query! However, in this example we made up the database so we don\\'t have a database to test the generated query. If you are testing this example, it could be useful to have this database created. Fortunately, you can use ChatGPT to generate this for you as well. One approach is using a modified version of the prompt above with slightly different instructions to generate a database schema:\\n\\n```mysql\\nTable departments, columns = [DepartmentId, DepartmentName]\\nTable students, columns = [DepartmentId, StudentId, StudentName]\\nCreate a valid database schema with the above tables and columns\\n```\\n\\nThe model generated the following schema:\\n\\n```mysql\\nCREATE TABLE departments (\\n  DepartmentId INT PRIMARY KEY,\\n  DepartmentName VARCHAR(50)\\n);\\n\\nCREATE TABLE students (\\n  DepartmentId INT,\\n  StudentId INT PRIMARY KEY,\\n  StudentName VARCHAR(50),\\n  FOREIGN KEY (DepartmentId) REFERENCES departments(DepartmentId)\\n);\\n```\\n\\nYou can create a temporary database using something like [sqliteonline.com](https://sqliteonline.com/).\\n\\nYou will also need dummy data to test if the original generated query was valid. Let\\'s use ChatGPT for this too! The prompt could look something like the following:\\n\\n```mysql\\nCREATE TABLE departments (\\n  DepartmentId INT PRIMARY KEY,\\n  DepartmentName VARCHAR(50)\\n);\\n\\nCREATE TABLE students (\\n  DepartmentId INT,\\n  StudentId INT PRIMARY KEY,\\n  StudentName VARCHAR(50),\\n  FOREIGN KEY (DepartmentId) REFERENCES departments(DepartmentId)\\n);\\n\\nGiven the database schema above, generate valid insert statements include 4 rows for each table.\\n```\\n\\nThe output with the insert statements:\\n\\n```mysql\\nINSERT INTO departments (DepartmentId, DepartmentName)\\nVALUES (1, \\'Computer Science\\'), (2, \\'Mathematics\\'), (3, \\'Physics\\'), (4, \\'Biology\\');\\n\\nINSERT INTO students (DepartmentId, StudentId, StudentName)\\nVALUES (1, 101, \\'John Doe\\'), (1, 102, \\'Jane Doe\\'), (2, 201, \\'Alice Smith\\'), (2, 202, \\'Bob Johnson\\');\\n```\\n\\nNow that you have the database and the dummy data, you can test the original query. Based on the dummy data, the result should be two rows with `Jane Doe` and `John Doe`.\\n\\n## Explain Code\\nIf you are learning to program in a certain language, it might be useful to prompt the model to explain certain bits of code. Let\\'s reuse the query generated above and ask the model to explain it.\\n\\nIf you are using the same System Message from before, be careful of how you are instructing the model. For example, if we use the following example, the model will complain that it is a code assistant in Python but it still provides an explanation. Sometimes the model refuses to generate what you are instructing because it\\'s designed to follow the System Message. \\n\\n*Prompt:*\\n\\n```mysql\\nSELECT students.StudentId, students.StudentName\\nFROM students\\nINNER JOIN departments\\nON students.DepartmentId = departments.DepartmentId\\nWHERE departments.DepartmentName = \\'Computer Science\\';\\n\\nExplain the above SQL statement.\\n```\\n\\n*Output:*\\n\\n```\\nSorry, as a code assistant in Python, I cannot generate SQL code. However, I can explain the purpose of the SQL statement provided. \\n\\nThis SQL statement selects the `StudentId` and `StudentName` columns from the `students` table, where the `DepartmentName` column in the `departments` table is equal to \\'Computer Science\\'. To achieve this, the statement performs an inner join on the `DepartmentId` column between the `students` and `departments` tables. \\n\\nIn simpler terms, it is selecting the names and IDs of students who are enrolled in the Computer Science department.\\n```\\n\\n## Editing Code\\nExample coming soon!\\n\\n## Debugging Code\\nExample coming soon!\\n\\n## Best practices\\nComing soon!\\n'}, {'path': '../documents/context-caching.md', 'content': '# Context Caching with Gemini 1.5 Flash\\n\\n\\nGoogle recently released a new feature called [context-caching](https://ai.google.dev/gemini-api/docs/caching?lang=python) which is available via the Gemini APIs through the Gemini 1.5 Pro and Gemini 1.5 Flash models. This guide provides a basic example of how to use context-caching with Gemini 1.5 Flash.\\n\\n\\n\\n\\nhttps://youtu.be/987Pd89EDPs?si=j43isgNb0uwH5AeI\\n\\n### The Use Case: Analyzing a Year\\'s Worth of ML Papers\\n\\nThe guide demonstrates how you can use context caching to analyze the summaries of all the [ML papers we\\'ve documented over the past year](https://github.com/dair-ai/ML-Papers-of-the-Week). We store these summaries in a text file, which can now be fed to the Gemini 1.5 Flash model and query efficiently. \\n\\n### The Process: Uploading, Caching, and Querying\\n\\n1. **Data Preparation:** First convert the readme file (containing the summaries) into a plain text file.\\n2. **Utilizing the Gemini API:** You can upload the text file using the Google `generativeai` library.\\n3. **Implementing Context Caching:**  A cache is created using the `caching.CachedContent.create()` function. This involves:\\n    * Specifying the Gemini Flash 1.5 model.\\n    * Providing a name for the cache.\\n    * Defining an instruction for the model (e.g., \"You are an expert AI researcher...\"). \\n    * Setting a time-to-live (TTL) for the cache (e.g., 15 minutes).\\n4. **Creating the Model:** We then create a generative model instance using the cached content.\\n5. **Querying:**  We can start querying the model with natural language questions like:\\n    * \"Can you please tell me the latest AI papers of the week?\"\\n    * \"Can you list the papers that mention Mamba? List the title of the paper and summary.\"\\n    * \"What are some of the innovations around long-context LLMs? List the title of the paper and summary.\"\\n\\nThe results were promising. The model accurately retrieved and summarized information from the text file. Context caching proved highly efficient, eliminating the need to repeatedly send the entire text file with each query.\\n\\nThis workflow has the potential to be a valuable tool for researchers, allowing them to:\\n\\n* Quickly analyze and query large amounts of research data.\\n* Retrieve specific findings without manually searching through documents.\\n* Conduct interactive research sessions without wasting prompt tokens.\\n\\nWe are excited to explore further applications of context caching, especially within more complex scenarios like agentic workflows. \\n\\n\\nThe notebook can be found below:\\n\\n\\n\\n\\n'}]\n"
     ]
    }
   ],
   "source": [
    "print(documents[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "919b644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model='gpt-4o-mini',\n",
    "    temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85acfeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing 0 doc(s) named: introduction.md\n",
      "Saving 0 doc(s) to ../documents/sum/introduction.md\n",
      "Summarizing 1 doc(s) named: coding.md\n",
      "Saving 1 doc(s) to ../documents/sum/coding.md\n",
      "Summarizing 2 doc(s) named: context-caching.md\n",
      "Saving 2 doc(s) to ../documents/sum/context-caching.md\n",
      "Summarizing 3 doc(s) named: finetuning-gpt4o.md\n",
      "Saving 3 doc(s) to ../documents/sum/finetuning-gpt4o.md\n",
      "Summarizing 4 doc(s) named: function_calling.md\n",
      "Saving 4 doc(s) to ../documents/sum/function_calling.md\n",
      "Summarizing 5 doc(s) named: generating_textbooks.md\n",
      "Saving 5 doc(s) to ../documents/sum/generating_textbooks.md\n",
      "Summarizing 6 doc(s) named: generating.md\n",
      "Saving 6 doc(s) to ../documents/sum/generating.md\n",
      "Summarizing 7 doc(s) named: pf.md\n",
      "Saving 7 doc(s) to ../documents/sum/pf.md\n",
      "Summarizing 8 doc(s) named: synthetic_rag.md\n",
      "Saving 8 doc(s) to ../documents/sum/synthetic_rag.md\n",
      "Summarizing 9 doc(s) named: workplace_casestudy.md\n",
      "Saving 9 doc(s) to ../documents/sum/workplace_casestudy.md\n",
      "Summarizing 10 doc(s) named: deep-research.md\n",
      "Saving 10 doc(s) to ../documents/sum/deep-research.md\n",
      "Summarizing 11 doc(s) named: optimizing-prompts.md\n",
      "Saving 11 doc(s) to ../documents/sum/optimizing-prompts.md\n",
      "Summarizing 12 doc(s) named: reasoning-llms.md\n",
      "Saving 12 doc(s) to ../documents/sum/reasoning-llms.md\n",
      "Summarizing 13 doc(s) named: open-domain.md\n",
      "Saving 13 doc(s) to ../documents/sum/open-domain.md\n",
      "Summarizing 14 doc(s) named: indirect-reasoning.md\n",
      "Saving 14 doc(s) to ../documents/sum/indirect-reasoning.md\n",
      "Summarizing 15 doc(s) named: explain-concept.md\n",
      "Saving 15 doc(s) to ../documents/sum/explain-concept.md\n",
      "Summarizing 16 doc(s) named: dsp.md\n",
      "Saving 16 doc(s) to ../documents/sum/dsp.md\n",
      "Summarizing 17 doc(s) named: graph.md\n",
      "Saving 17 doc(s) to ../documents/sum/graph.md\n",
      "Summarizing 18 doc(s) named: meta-prompting.md\n",
      "Saving 18 doc(s) to ../documents/sum/meta-prompting.md\n",
      "Summarizing 19 doc(s) named: pal.md\n",
      "Saving 19 doc(s) to ../documents/sum/pal.md\n",
      "Summarizing 20 doc(s) named: rag.md\n",
      "Saving 20 doc(s) to ../documents/sum/rag.md\n",
      "Summarizing 21 doc(s) named: reflexion.md\n",
      "Saving 21 doc(s) to ../documents/sum/reflexion.md\n",
      "Summarizing 22 doc(s) named: zeroshot.md\n",
      "Saving 22 doc(s) to ../documents/sum/zeroshot.md\n",
      "Summarizing 23 doc(s) named: components.md\n",
      "Saving 23 doc(s) to ../documents/sum/components.md\n",
      "Summarizing 24 doc(s) named: settings.md\n",
      "Saving 24 doc(s) to ../documents/sum/settings.md\n",
      "Summarizing 25 doc(s) named: tips.md\n",
      "Saving 25 doc(s) to ../documents/sum/tips.md\n",
      "Summarizing 26 doc(s) named: chatgpt.md\n",
      "Saving 26 doc(s) to ../documents/sum/chatgpt.md\n",
      "Summarizing 27 doc(s) named: claude-3.md\n",
      "Saving 27 doc(s) to ../documents/sum/claude-3.md\n",
      "Summarizing 28 doc(s) named: code-llama.md\n",
      "Saving 28 doc(s) to ../documents/sum/code-llama.md\n",
      "Summarizing 29 doc(s) named: collection.md\n",
      "Saving 29 doc(s) to ../documents/sum/collection.md\n",
      "Summarizing 30 doc(s) named: flan.md\n",
      "Saving 30 doc(s) to ../documents/sum/flan.md\n",
      "Summarizing 31 doc(s) named: gemini-advanced.md\n",
      "Saving 31 doc(s) to ../documents/sum/gemini-advanced.md\n",
      "Summarizing 32 doc(s) named: gemini-pro.md\n",
      "Saving 32 doc(s) to ../documents/sum/gemini-pro.md\n",
      "Summarizing 33 doc(s) named: gemini.md\n",
      "Saving 33 doc(s) to ../documents/sum/gemini.md\n",
      "Summarizing 34 doc(s) named: gemma.md\n",
      "Saving 34 doc(s) to ../documents/sum/gemma.md\n",
      "Summarizing 35 doc(s) named: gpt-4.md\n",
      "Saving 35 doc(s) to ../documents/sum/gpt-4.md\n",
      "Summarizing 36 doc(s) named: grok-1.md\n",
      "Saving 36 doc(s) to ../documents/sum/grok-1.md\n",
      "Summarizing 37 doc(s) named: llama-3.md\n",
      "Saving 37 doc(s) to ../documents/sum/llama-3.md\n",
      "Summarizing 38 doc(s) named: llama.md\n",
      "Saving 38 doc(s) to ../documents/sum/llama.md\n",
      "Summarizing 39 doc(s) named: mistral-7b.md\n",
      "Saving 39 doc(s) to ../documents/sum/mistral-7b.md\n",
      "Summarizing 40 doc(s) named: mistral-large.md\n",
      "Saving 40 doc(s) to ../documents/sum/mistral-large.md\n",
      "Summarizing 41 doc(s) named: mixtral-8x22b.md\n",
      "Saving 41 doc(s) to ../documents/sum/mixtral-8x22b.md\n",
      "Summarizing 42 doc(s) named: mixtral.md\n",
      "Saving 42 doc(s) to ../documents/sum/mixtral.md\n",
      "Summarizing 43 doc(s) named: olmo.md\n",
      "Saving 43 doc(s) to ../documents/sum/olmo.md\n",
      "Summarizing 44 doc(s) named: phi-2.md\n",
      "Saving 44 doc(s) to ../documents/sum/phi-2.md\n",
      "Summarizing 45 doc(s) named: sora.md\n",
      "Saving 45 doc(s) to ../documents/sum/sora.md\n",
      "Summarizing 46 doc(s) named: jailbreaking-llms.md\n",
      "Saving 46 doc(s) to ../documents/sum/jailbreaking-llms.md\n",
      "Summarizing 47 doc(s) named: prompt-injection.md\n",
      "Saving 47 doc(s) to ../documents/sum/prompt-injection.md\n",
      "Summarizing 48 doc(s) named: prompt-leaking.md\n",
      "Saving 48 doc(s) to ../documents/sum/prompt-leaking.md\n",
      "Summarizing 49 doc(s) named: sentiment-fewshot.md\n",
      "Saving 49 doc(s) to ../documents/sum/sentiment-fewshot.md\n",
      "Summarizing 50 doc(s) named: sentiment.md\n",
      "Saving 50 doc(s) to ../documents/sum/sentiment.md\n",
      "Summarizing 51 doc(s) named: code-snippet.md\n",
      "Saving 51 doc(s) to ../documents/sum/code-snippet.md\n",
      "Summarizing 52 doc(s) named: mysql-query.md\n",
      "Saving 52 doc(s) to ../documents/sum/mysql-query.md\n",
      "Summarizing 53 doc(s) named: tikz.md\n",
      "Saving 53 doc(s) to ../documents/sum/tikz.md\n",
      "Summarizing 54 doc(s) named: infinite-primes.md\n",
      "Saving 54 doc(s) to ../documents/sum/infinite-primes.md\n",
      "Summarizing 55 doc(s) named: rhymes.md\n",
      "Saving 55 doc(s) to ../documents/sum/rhymes.md\n",
      "Summarizing 56 doc(s) named: new-words.md\n",
      "Saving 56 doc(s) to ../documents/sum/new-words.md\n",
      "Summarizing 57 doc(s) named: interdisciplinary.md\n",
      "Saving 57 doc(s) to ../documents/sum/interdisciplinary.md\n",
      "Summarizing 58 doc(s) named: plato-dialogue.md\n",
      "Saving 58 doc(s) to ../documents/sum/plato-dialogue.md\n",
      "Summarizing 59 doc(s) named: alphabet-person.md\n",
      "Saving 59 doc(s) to ../documents/sum/alphabet-person.md\n",
      "Summarizing 60 doc(s) named: extract-models.md\n",
      "Saving 60 doc(s) to ../documents/sum/extract-models.md\n",
      "Summarizing 61 doc(s) named: composite-functions.md\n",
      "Saving 61 doc(s) to ../documents/sum/composite-functions.md\n",
      "Summarizing 62 doc(s) named: odd-numbers.md\n",
      "Saving 62 doc(s) to ../documents/sum/odd-numbers.md\n",
      "Summarizing 63 doc(s) named: closed-domain.md\n",
      "Saving 63 doc(s) to ../documents/sum/closed-domain.md\n",
      "Summarizing 64 doc(s) named: science-qa.md\n",
      "Saving 64 doc(s) to ../documents/sum/science-qa.md\n",
      "Summarizing 65 doc(s) named: physical-reasoning.md\n",
      "Saving 65 doc(s) to ../documents/sum/physical-reasoning.md\n",
      "Summarizing 66 doc(s) named: identify-hallucination.md\n",
      "Saving 66 doc(s) to ../documents/sum/identify-hallucination.md\n",
      "Summarizing 67 doc(s) named: groq.md\n",
      "Saving 67 doc(s) to ../documents/sum/groq.md\n",
      "Summarizing 68 doc(s) named: guided-cot.md\n",
      "Saving 68 doc(s) to ../documents/sum/guided-cot.md\n",
      "Summarizing 69 doc(s) named: infini-attention.md\n",
      "Saving 69 doc(s) to ../documents/sum/infini-attention.md\n",
      "Summarizing 70 doc(s) named: llm-agents.md\n",
      "Saving 70 doc(s) to ../documents/sum/llm-agents.md\n",
      "Summarizing 71 doc(s) named: llm-reasoning.md\n",
      "Saving 71 doc(s) to ../documents/sum/llm-reasoning.md\n",
      "Summarizing 72 doc(s) named: llm-recall.md\n",
      "Saving 72 doc(s) to ../documents/sum/llm-recall.md\n",
      "Summarizing 73 doc(s) named: llm-tokenization.md\n",
      "Saving 73 doc(s) to ../documents/sum/llm-tokenization.md\n",
      "Summarizing 74 doc(s) named: rag_hallucinations.md\n",
      "Saving 74 doc(s) to ../documents/sum/rag_hallucinations.md\n",
      "Summarizing 75 doc(s) named: rag-faithfulness.md\n",
      "Saving 75 doc(s) to ../documents/sum/rag-faithfulness.md\n",
      "Summarizing 76 doc(s) named: synthetic_data.md\n",
      "Saving 76 doc(s) to ../documents/sum/synthetic_data.md\n",
      "Summarizing 77 doc(s) named: thoughtsculpt.md\n",
      "Saving 77 doc(s) to ../documents/sum/thoughtsculpt.md\n",
      "Summarizing 78 doc(s) named: trustworthiness-in-llms.md\n",
      "Saving 78 doc(s) to ../documents/sum/trustworthiness-in-llms.md\n",
      "Summarizing 79 doc(s) named: adversarial.md\n",
      "Saving 79 doc(s) to ../documents/sum/adversarial.md\n",
      "Summarizing 80 doc(s) named: biases.md\n",
      "Saving 80 doc(s) to ../documents/sum/biases.md\n",
      "Summarizing 81 doc(s) named: factuality.md\n",
      "Saving 81 doc(s) to ../documents/sum/factuality.md\n",
      "Summarizing 82 doc(s) named: rag-1.md\n",
      "Saving 82 doc(s) to ../documents/sum/rag-1.md\n",
      "Summarizing 83 doc(s) named: activeprompt.md\n",
      "Saving 83 doc(s) to ../documents/sum/activeprompt.md\n",
      "Summarizing 84 doc(s) named: ape.md\n",
      "Saving 84 doc(s) to ../documents/sum/ape.md\n",
      "Summarizing 85 doc(s) named: art.md\n",
      "Saving 85 doc(s) to ../documents/sum/art.md\n",
      "Summarizing 86 doc(s) named: consistency.md\n",
      "Saving 86 doc(s) to ../documents/sum/consistency.md\n",
      "Summarizing 87 doc(s) named: cot.md\n",
      "Saving 87 doc(s) to ../documents/sum/cot.md\n",
      "Summarizing 88 doc(s) named: fewshot.md\n",
      "Saving 88 doc(s) to ../documents/sum/fewshot.md\n",
      "Summarizing 89 doc(s) named: knowledge.md\n",
      "Saving 89 doc(s) to ../documents/sum/knowledge.md\n",
      "Summarizing 90 doc(s) named: multimodalcot.md\n",
      "Saving 90 doc(s) to ../documents/sum/multimodalcot.md\n",
      "Summarizing 91 doc(s) named: prompt_chaining.md\n",
      "Saving 91 doc(s) to ../documents/sum/prompt_chaining.md\n",
      "Summarizing 92 doc(s) named: react.md\n",
      "Saving 92 doc(s) to ../documents/sum/react.md\n",
      "Summarizing 93 doc(s) named: tot.md\n",
      "Saving 93 doc(s) to ../documents/sum/tot.md\n"
     ]
    }
   ],
   "source": [
    "new_path = '../documents/sum'\n",
    "for index, doc in enumerate(documents):\n",
    "    messages = [\n",
    "        HumanMessage(content=PROMPT.format(doc['content']))\n",
    "    ]\n",
    "\n",
    "    print(f'Summarizing {index} doc(s) named: {doc['name']}')\n",
    "    res = llm.invoke(messages)\n",
    "\n",
    "    content = res.content.split('</think>')[-1]\n",
    "\n",
    "    new_pwd = f'{new_path}/{doc['name']}'\n",
    "    print(f'Saving {index} doc(s) to {new_pwd}')\n",
    "    with open(new_pwd, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promptneering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
