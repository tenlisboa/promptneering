The paper by Liu et al. (2022) explores the concept of generating knowledge to enhance the predictive capabilities of large language models (LLMs), particularly for tasks requiring commonsense reasoning. It begins with a simple prompt about golf, revealing LLM limitations when lacking contextual knowledge. To address this, the authors generate relevant knowledge snippets, such as "The objective of golf is to play a set of holes in the least number of strokes," and integrate them into a question-answer format. For example, when asked, "Part of golf is trying to get a higher point total than others. Yes or No?" and provided with the knowledge, the model confidently answers "No," clarifying that the goal is to minimize strokes, while a second attempt with different knowledge yields a less confident "Yes." This illustrates the impact of knowledge generation on LLM performance, emphasizing the importance of context in accurate predictions.