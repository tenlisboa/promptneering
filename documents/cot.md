Chain-of-Thought (CoT) prompting, introduced by Wei et al. (2022), enhances reasoning capabilities by incorporating intermediate steps, which can be combined with few-shot prompting for improved results on complex tasks. For example, in the prompt "The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1," the output is derived by adding the odd numbers, resulting in "Adding all the odd numbers (9, 15, 1) gives 25. The answer is False." Zero-shot CoT, proposed by Kojima et al. (2022), adds "Let's think step by step" to prompts, improving accuracy in reasoning tasks, as shown in the apple problem where the output becomes a detailed step-by-step explanation. Automatic Chain-of-Thought (Auto-CoT) aims to streamline the process of generating reasoning chains by clustering questions and sampling diverse demonstrations, thus reducing manual effort while maintaining effectiveness. The Auto-CoT process involves question clustering and demonstration sampling, utilizing heuristics to ensure the quality of generated reasoning chains.