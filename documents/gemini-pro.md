Google has launched Gemini 1.5 Pro, a compute-efficient multimodal mixture-of-experts model designed for recalling and reasoning over long-form content, capable of processing documents with millions of tokens, including video and audio. It excels in long-document QA, long-video QA, and long-context ASR, achieving near-perfect retrieval rates of over 99% for up to 10 million tokens, significantly surpassing previous models. A new experimental 1 million token context window model will be available in Google AI Studio, enabling diverse applications like Q&A over large PDFs and lengthy videos. The architecture is based on a sparse mixture-of-experts Transformer, allowing efficient training and serving while maintaining long-context understanding. Gemini 1.5 Pro demonstrates impressive capabilities in long document analysis, video understanding, code reasoning, and multilingual translation, as illustrated by examples such as summarizing a PDF with the prompt `"What is the paper about?"` and extracting information from a video lecture. The model's performance is notable across various benchmarks, outperforming its predecessor, Gemini 1.0 Ultra, while using less training compute.