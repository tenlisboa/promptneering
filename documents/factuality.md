LLMs often generate coherent but potentially fabricated responses, and enhancing prompts can lead to more accurate and factual outputs. Solutions to improve factuality include providing ground truth, such as a related article or Wikipedia entry, to minimize the generation of false information, configuring the model to produce less diverse responses by adjusting probability parameters, and instructing it to admit uncertainty (e.g., "I don't know"). Additionally, including a mix of known and unknown question-response examples in the prompt can be beneficial. For instance, in the prompt, "Q: What is an atom? A: An atom is a tiny particle that makes up everything. Q: Who is Alvan Muntz? A: ? Q: What is Kozar-09? A: ? Q: How many moons does Mars have? A: Two, Phobos and Deimos. Q: Who is Neto Beto Roberto?" the model correctly responds with "A: ?" for the made-up name, illustrating the importance of refining questions to improve accuracy.