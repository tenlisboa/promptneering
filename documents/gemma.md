Google DeepMind has released Gemma, a series of open language models inspired by the technology behind Gemini, featuring 2B and 7B models trained on 2T and 6T tokens, respectively. These models, which utilize a transformer decoder architecture with enhancements like multi-query attention and RoPE embeddings, outperform Llama 2 7B and Mistral 7B on various benchmarks, particularly in math, science, and code tasks. The instruction-tuned models are fine-tuned using a mix of synthetic and human-generated prompts, focusing solely on English datasets. For prompting, the Gemma 7B model can be used in zero-shot or few-shot formats, with specific control tokens for user and model turns, as illustrated in examples like ```user Generate a Python function that multiplies two numbers model``` and ```user Explain why the sky is blue model```. Additionally, Gemma has been evaluated for safety and instruction-following capabilities, employing debiasing techniques to mitigate risks associated with large language models. Resources for using Gemma include Colab and Kaggle notebooks, and it is available in the NVIDIA AI Playground.