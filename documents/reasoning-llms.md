The Reasoning LLMs Guide provides an overview of large reasoning models (LRMs) designed for native thinking and chain-of-thought tasks, with examples like Gemini 2.5 Pro and Claude 3.7 Sonnet. Key sections include a summary of top reasoning models, design patterns, and use cases such as planning for agentic systems, agentic RAG, LLM-as-a-Judge, and visual reasoning. Usage tips emphasize strategic reasoning, explicit instructions, and structured inputs, while highlighting the importance of balancing thinking time and avoiding manual chain-of-thought prompting. Limitations include output quality issues, reasoning affecting instruction-following, and high costs. The guide also suggests next steps for learning about reasoning LLM applications and offers resources for further exploration. An example prompt to test reasoning capabilities is: ``What is the sum of the first 50 prime numbers? Generate and run Python code for the calculation, and make sure you get all 50. Provide the final sum clearly.``