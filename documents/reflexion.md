Reflexion is a framework designed to enhance language-based agents through linguistic feedback, enabling them to learn from past mistakes via a process called self-reflection. It consists of three main components: an Actor that generates text and actions based on observations, an Evaluator that scores the Actor's outputs, and a Self-Reflection model that provides verbal reinforcement for improvement. The Reflexion process involves defining a task, generating a trajectory, evaluating it, reflecting, and generating the next trajectory. Experimental results show that Reflexion significantly improves performance in decision-making tasks (e.g., AlfWorld), reasoning (e.g., HotPotQA), and programming (e.g., HumanEval). It is particularly useful for agents that learn through trial and error, require nuanced feedback, and benefit from interpretability and explicit memory. However, it has limitations, including reliance on self-evaluation and constraints in long-term memory management. Examples of the Reflexion process include "Chain-of-Thought" and "ReAct" models, which enhance the agent's learning capabilities.