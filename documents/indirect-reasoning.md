Zhang et al. (2024) introduced an indirect reasoning method to enhance the reasoning capabilities of LLMs by utilizing contrapositives and contradictions for tasks like factual reasoning and mathematical proof. This method involves two main steps: improving LLM comprehensibility through data and rule augmentation, and creating prompt templates to encourage indirect reasoning via proof by contradiction. Experiments with models such as GPT-3.5-turbo and Gemini-pro demonstrated a significant accuracy increase of 27.33% in factual reasoning and 31.43% in mathematical proof compared to traditional direct reasoning approaches. An example of a zero-shot template for proof-by-contradiction is: ```If a+|a|=0, try to prove that a```.